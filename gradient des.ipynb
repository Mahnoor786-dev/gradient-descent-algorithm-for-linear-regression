{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0ayo_PpC9IX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        " \n",
        "def gradient_descent(X, y, alpha, iterations):\n",
        "  #set an array for theta0, theta1\n",
        "  theta = np.array([0,0])\n",
        "  #get number of samples in features X\n",
        "  m = length(X)\n",
        "  #iterate to coverge value of theta\n",
        "  for i in range(iterations):\n",
        "    #predict the known label y\n",
        "    y_predict = theta[1]*X + theta[0]\n",
        "    #calculate the gradient of cost w.r.t theta0, theta1\n",
        "    grad_theta0 = (2/m)*np.sum(y_predict - y)\n",
        "    grad_theta1 = (2/m)*np.sum(X*(y_predict - y))\n",
        "    #update the theta (parameters)\n",
        "    theta[1]=  theta[1]- alpha*grad_theta1\n",
        "    theta[0]=  theta[0]- alpha*grad_theta0\n",
        "       \n",
        "def predict(theta,X):\n",
        "  return theta[1]*X + theta[0]\n",
        "      \n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return np.mean((np.square(y_true - y_pred)))\n",
        "\n",
        "alpha = 0.01\n",
        "iterations=1000\n",
        "gradient_descent(X,y,alpha,iterations)\n",
        "\n",
        "\n",
        "predicted_outputs = predict(theta, X)\n",
        "MSE = mean_squared_error(y, predicted_outputs)\n",
        "print(MSE)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X,y)\n",
        "plt.scatter(new_hours,predict)\n",
        "plt.plot(X,existing)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
